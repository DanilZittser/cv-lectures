{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Информация\n",
    "- *Автор*: Зитцер Данил\n",
    "- *Дата*: среда, 8 октября 2021 г., 10:16:09\n",
    "- *Описание*: Введение в OpenVINO Toolkit\n",
    "- *Полезные ссылки*:\n",
    "    - [OpenVINO Documentation](https://docs.openvinotoolkit.org/latest/index.html)\n",
    "    - [OpenVINO on GitHub](https://github.com/openvinotoolkit)\n",
    "    - [OpenVINO Model Zoo](https://github.com/openvinotoolkit/open_model_zoo)\n",
    "    - [OpenVINO Jupyter Notebooks](https://github.com/openvinotoolkit/openvino_notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenVINO Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Использование OpenVINO Toolkit для развёртывания ускоренных приложений глубокого обучения](https://raw.githubusercontent.com/intel-iot-devkit/smart-video-workshop/master/presentations/OpenVINO_Training_Part1_2021.4.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель классификации\n",
    "\n",
    "[mobilenet-v3-small-1.0-224-tf](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/public/mobilenet-v3-small-1.0-224-tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:06.783233Z",
     "start_time": "2021-10-25T09:23:06.524996Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from openvino.inference_engine import IECore\n",
    "from statistics import mean\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:06.903434Z",
     "start_time": "2021-10-25T09:23:06.784647Z"
    }
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "\n",
    "net = ie.read_network(\n",
    "    model='./../models/v3-small_224_1.0_float.xml',\n",
    "    weights='./../models/v3-small_224_1.0_float.bin',\n",
    ")\n",
    "exec_net = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "input_key = next(iter(exec_net.input_info))\n",
    "output_key = next(iter(exec_net.outputs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:06.907617Z",
     "start_time": "2021-10-25T09:23:06.904693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "MobilenetV3/Predictions/Softmax\n"
     ]
    }
   ],
   "source": [
    "print(input_key)\n",
    "print(output_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка словаря объектов ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:06.915151Z",
     "start_time": "2021-10-25T09:23:06.909108Z"
    }
   },
   "outputs": [],
   "source": [
    "imagenet_classes = json.loads(open('./../utils/imagenet_class_index.json').read())\n",
    "# +1, так как 0 отведён под класс background\n",
    "imagenet_classes = {int(key) + 1: value[1] for key, value in imagenet_classes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инференс модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:28.879104Z",
     "start_time": "2021-10-25T09:23:06.916029Z"
    }
   },
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('./../videos/sheep.mp4')\n",
    "\n",
    "success, frame = capture.read()\n",
    "\n",
    "if not success:\n",
    "    raise ValueError(f'Can not read first frame')\n",
    "    \n",
    "inference_times = []\n",
    "\n",
    "while True:\n",
    "    success, frame = capture.read()  # bgr\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # подготовка кадра на вход нейронной сети: [Any, Any, 3] --> [1, 3, 224, 224]\n",
    "    prepared_input = cv2.dnn.blobFromImage(image=frame, size=(224, 224))\n",
    "    # инференс модели\n",
    "    tic = time()\n",
    "    result = exec_net.infer(inputs={input_key: prepared_input})[output_key]\n",
    "    toc = time()\n",
    "    inference_times.append(toc - tic)\n",
    "    \n",
    "    result_index = result.squeeze().argmax()\n",
    "    \n",
    "    cv2.putText(frame, f'object: {imagenet_classes[result_index]}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'fps: {1.0 / mean(inference_times):.0f}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Press Q for exit', frame)\n",
    "\n",
    "    key = cv2.waitKey(40) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель детекции\n",
    "\n",
    "[person-detection-0200](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/person-detection-0200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:29.021126Z",
     "start_time": "2021-10-25T09:23:28.879961Z"
    }
   },
   "outputs": [],
   "source": [
    "ie = IECore()\n",
    "\n",
    "net = ie.read_network(\n",
    "    model='./../models/person-detection-0200.xml',\n",
    "    weights='./../models/person-detection-0200.bin',\n",
    ")\n",
    "exec_net = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "input_key = next(iter(exec_net.input_info))\n",
    "output_key = next(iter(exec_net.outputs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:29.024394Z",
     "start_time": "2021-10-25T09:23:29.022113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image\n",
      "detection_out\n"
     ]
    }
   ],
   "source": [
    "print(input_key)\n",
    "print(output_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Инференс модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-25T09:23:33.376977Z",
     "start_time": "2021-10-25T09:23:29.025164Z"
    }
   },
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('./../videos/pedestrians.mp4')\n",
    "\n",
    "success, frame = capture.read()\n",
    "\n",
    "if not success:\n",
    "    raise ValueError(f'Can not read first frame')\n",
    "    \n",
    "inference_times = []\n",
    "\n",
    "while True:\n",
    "    success, frame = capture.read()  # bgr\n",
    "\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # подготовка кадра на вход нейронной сети: [Any, Any, 3] --> [1, 3, 224, 224]\n",
    "    prepared_input = cv2.dnn.blobFromImage(image=frame, size=(256, 256))\n",
    "    # инференс модели\n",
    "    tic = time()\n",
    "    result = exec_net.infer(inputs={input_key: prepared_input})[output_key]\n",
    "    toc = time()\n",
    "    inference_times.append(toc - tic)\n",
    "    \n",
    "    result = result[0, 0, result[0, 0, :, 2] > 0.8]\n",
    "    \n",
    "    for image_id, label, confidence, x1, y1, x2, y2 in result:\n",
    "        x1, x2 = int(x1*frame.shape[1]), int(x2*frame.shape[1])\n",
    "        y1, y2 = int(y1*frame.shape[0]), int(y2*frame.shape[0])\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        cv2.putText(frame, f'{confidence:.1%}', (x1 + 10, y2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "    \n",
    "#     cv2.putText(frame, f'object: {imagenet_classes[result_index]}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f'fps: {1.0 / mean(inference_times):.0f}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Press Q for exit', cv2.resize(frame, (0, 0), fx=0.5, fy=0.5))\n",
    "\n",
    "    key = cv2.waitKey(40) & 0xFF\n",
    "\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lectures",
   "language": "python",
   "name": "lectures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
